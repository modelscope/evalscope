# 构建评测指数（Index）

通过 **Collection**，你可以在 EvalScope 中定义属于自己的 **评测指数（Index）**：  
把多个数据集按业务价值“配比”在一起，一次跑测，得到贴合你真实场景的综合评分。

---

## 什么时候需要自定义 Index？

很多团队在选型时只看单一基准（例如 MMLU 分数），但往往遇到几个典型问题：

- **单一数据集不等于真实场景**  
  你的实际场景可能是：
  - RAG 问答（知识库检索 + 回答）
  - 金融/法律等垂直领域分析
  - 代码补全与代码审查
  这些往往难以被某一个公开数据集完全覆盖。

- **公共榜单不等于你的最佳模型**  
  榜单关注“通用能力”，而你更关心“业务价值”：  
  - 哪个模型更适合你的 RAG workflow？  
  - 哪个模型在你关心的领域错误率最低？  
  - 哪个模型在成本和效果之间更平衡？

- **你需要一个“反映自己价值观”的指数**  
  就像：
  - [Artificial Analysis Intelligence Index](https://artificialanalysis.ai/methodology/intelligence-benchmarking#intelligence-index-evaluation-suite-summary) 聚焦通用智力能力
  - [Vals Index](https://www.vals.ai/benchmarks/vals_index) 聚焦商业价值

  你也可以定义一个 **只服务于你业务决策的 Index**。

EvalScope 的 **Collection** 就是为此设计的：  
你可以把多个数据集“打包”，按业务重要性设置权重，形成一个真正属于你的评测指数。

---

## 核心心智模型：Collection = 带权重的多数据集评测

可以把 Collection 理解为：

> 一个描述“我关心什么，以及各占多少比重”的 **配置文件**  
> → 抽样出一个混合数据集  
> → 用 EvalScope 一次性评测  
> → 得到一份按你价值观加权的“模型综合得分表”。

从使用者角度，你只需要关心三件事：

1. 我要评哪些 **数据集**？
2. 每个数据集在我的决策里 **占多少权重**？
3. 我希望从这些数据集中 **怎么抽样**（多少样本、如何分布）？

---

## 从 0 到 1：如何使用 Collection 构建 Index？

下面是一个最小可用的工作流，帮助你快速上手。

### 1. 定义 Schema：声明“我在意什么”

在 **Schema** 中，你需要做两件事：

- 选定要纳入 Index 的 **数据集列表**  
  例如：
  - `gsm8k`：基础数学推理
  - 一个内部构造的 RAG 问答数据集
  - 一个代码补全数据集

- 为每个数据集设置 **权重（weight）**  
  权重可以反映你对不同能力维度的重视程度：
  - RAG 场景占 50%
  - 金融问答占 30%
  - 一般推理能力占 20%

**更多细节请见：** [定义你的 Schema](schema.md)。

---

### 2. 采样数据：从多个数据集中抽出代表性样本

基于 Schema，EvalScope 可以为你生成一个 **混合数据集 JSONL**。  
你可以通过几种常见策略来控制采样方式：

- **按权重采样**：数据量大致按权重比例分配；
- **分层采样**：不同难度等级/子任务都能被覆盖；
- **均匀采样**：每个数据集取固定数量样本，方便做对比。

最终得到的是一个“已经混好”的 JSONL 文件，后续评测只需要对这个 JSONL 跑一遍即可。

**采样方式与命令示例：** 见 [如何采样](sample.md)。

---

### 3. 统一评测：一次跑出你的专属指数得分

拿到混合 JSONL 以后，你可以：

- 像评测普通数据集一样调用 `evalscope eval`
- 一次性得到：
  - 各个子数据集的得分
  - 按权重聚合后的 **Index 总分**
  - 对应的详细日志、预测、评审与报告

评测完成后，你可以用：

- 报表汇总不同模型在同一个 Index 下的表现；
- EvalScope 的 **可视化应用（`evalscope app`）** 直观对比模型优劣。

**具体评测命令与示例输出：** 见 [如何评测](evaluate.md)。


:::{toctree}
:maxdepth: 1

schema.md
sample.md
evaluate.md
:::
