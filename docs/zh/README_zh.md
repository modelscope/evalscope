[English](README.md) | ç®€ä½“ä¸­æ–‡

![](_static/images/evalscope.jpeg)

<p align="center">
<a href="https://pypi.org/project/evalscope"><img alt="PyPI - Downloads" src="https://img.shields.io/pypi/dm/evalscope">
</a>
<a href="https://github.com/modelscope/evalscope/pulls"><img src="https://img.shields.io/badge/PR-welcome-55EB99.svg"></a>
<p>

## ğŸ“– ç›®å½•
- [ç®€ä»‹](#ç®€ä»‹)
- [æ–°é—»](#æ–°é—»)
- [ç¯å¢ƒå‡†å¤‡](#ç¯å¢ƒå‡†å¤‡)
- [å¿«é€Ÿå¼€å§‹](#å¿«é€Ÿå¼€å§‹)
- [æ•°æ®é›†åˆ—è¡¨](#æ•°æ®é›†åˆ—è¡¨)
- [Leaderboardæ¦œå•](#leaderboard-æ¦œå•)
- [å®éªŒå’ŒæŠ¥å‘Š](#å®éªŒå’ŒæŠ¥å‘Š)
- [æ€§èƒ½è¯„æµ‹å·¥å…·](#æ€§èƒ½è¯„æµ‹å·¥å…·)


## ğŸ“ ç®€ä»‹
å¤§å‹è¯­è¨€æ¨¡å‹è¯„ä¼°ï¼ˆLLMs evaluationï¼‰å·²æˆä¸ºè¯„ä»·å’Œæ”¹è¿›å¤§æ¨¡å‹çš„é‡è¦æµç¨‹å’Œæ‰‹æ®µï¼Œä¸ºäº†æ›´å¥½åœ°æ”¯æŒå¤§æ¨¡å‹çš„è¯„æµ‹ï¼Œæˆ‘ä»¬æå‡ºäº†EvalScopeæ¡†æ¶ï¼Œè¯¥æ¡†æ¶ä¸»è¦åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªéƒ¨åˆ†ï¼š

![](_static/images/evalscope_framework.png)
*EvalScope æ¶æ„å›¾.*

- é¢„ç½®äº†å¤šä¸ªå¸¸ç”¨çš„æµ‹è¯•åŸºå‡†æ•°æ®é›†ï¼ŒåŒ…æ‹¬ï¼šMMLUã€CMMLUã€C-Evalã€GSM8Kã€ARCã€HellaSwagã€TruthfulQAã€MATHã€HumanEvalç­‰
- å¸¸ç”¨è¯„ä¼°æŒ‡æ ‡ï¼ˆmetricsï¼‰çš„å®ç°
- ç»Ÿä¸€modelæ¥å…¥ï¼Œå…¼å®¹å¤šä¸ªç³»åˆ—æ¨¡å‹çš„generateã€chatæ¥å£
- è‡ªåŠ¨è¯„ä¼°ï¼ˆevaluatorï¼‰ï¼š
    - å®¢è§‚é¢˜è‡ªåŠ¨è¯„ä¼°
    - ä½¿ç”¨ä¸“å®¶æ¨¡å‹å®ç°å¤æ‚ä»»åŠ¡çš„è‡ªåŠ¨è¯„ä¼°
- è¯„ä¼°æŠ¥å‘Šç”Ÿæˆ
- ç«æŠ€åœºæ¨¡å¼(Arena)
- å¯è§†åŒ–å·¥å…·
- [æ¨¡å‹æ€§èƒ½è¯„ä¼°](evalscope/perf/README.md)
- æ”¯æŒOpenCompassä½œä¸ºè¯„æµ‹åæ®µï¼Œå¯¹å…¶è¿›è¡Œäº†é«˜çº§å°è£…å’Œä»»åŠ¡ç®€åŒ–ï¼Œæ‚¨å¯ä»¥æ›´è½»æ¾åœ°æäº¤ä»»åŠ¡åˆ°OpenCompassè¿›è¡Œè¯„ä¼°ã€‚
- æ”¯æŒVLMEvalKitä½œä¸ºè¯„æµ‹åç«¯ï¼Œé€šè¿‡EvalScopeä½œä¸ºå…¥å£ï¼Œå‘èµ·VLMEvalKitçš„å¤šæ¨¡æ€è¯„æµ‹ä»»åŠ¡ï¼Œæ”¯æŒå¤šç§å¤šæ¨¡æ€æ¨¡å‹å’Œæ•°æ®é›†ã€‚
- å…¨é“¾è·¯æ”¯æŒï¼šé€šè¿‡ä¸SWIFTçš„æ— ç¼é›†æˆï¼Œæ‚¨å¯ä»¥è½»æ¾åœ°è®­ç»ƒå’Œéƒ¨ç½²æ¨¡å‹æœåŠ¡ï¼Œå‘èµ·è¯„æµ‹ä»»åŠ¡ï¼ŒæŸ¥çœ‹è¯„æµ‹æŠ¥å‘Šï¼Œå®ç°ä¸€ç«™å¼å¤§æ¨¡å‹å¼€å‘æµç¨‹ã€‚

**ç‰¹ç‚¹**
- è½»é‡åŒ–ï¼Œå°½é‡å‡å°‘ä¸å¿…è¦çš„æŠ½è±¡å’Œé…ç½®
- æ˜“äºå®šåˆ¶
  - ä»…éœ€å®ç°ä¸€ä¸ªç±»å³å¯æ¥å…¥æ–°çš„æ•°æ®é›†
  - æ¨¡å‹å¯æ‰˜ç®¡åœ¨[ModelScope](https://modelscope.cn)ä¸Šï¼Œä»…éœ€model idå³å¯ä¸€é”®å‘èµ·è¯„æµ‹
  - æ”¯æŒæœ¬åœ°æ¨¡å‹å¯éƒ¨ç½²åœ¨æœ¬åœ°
  - è¯„ä¼°æŠ¥å‘Šå¯è§†åŒ–å±•ç°
- ä¸°å¯Œçš„è¯„ä¼°æŒ‡æ ‡
- model-basedè‡ªåŠ¨è¯„ä¼°æµç¨‹ï¼Œæ”¯æŒå¤šç§è¯„ä¼°æ¨¡å¼
  - Single mode: ä¸“å®¶æ¨¡å‹å¯¹å•ä¸ªæ¨¡å‹æ‰“åˆ†
  - Pairwise-baseline mode: ä¸ baseline æ¨¡å‹å¯¹æ¯”
  - Pairwise (all) mode: å…¨éƒ¨æ¨¡å‹ä¸¤ä¸¤å¯¹æ¯”


## ğŸ‰ æ–°é—»
- **[2024.07.31]** é‡è¦ä¿®æ”¹ï¼š`llmuses`åŒ…åä¿®æ”¹ä¸º`evalscope`ï¼Œè¯·åŒæ­¥ä¿®æ”¹æ‚¨çš„ä»£ç 
- **[2024.07.26]** æ”¯æŒ**VLMEvalKit**ä½œä¸ºç¬¬ä¸‰æ–¹è¯„æµ‹æ¡†æ¶ï¼Œå‘èµ·å¤šæ¨¡æ€æ¨¡å‹è¯„æµ‹ä»»åŠ¡ï¼Œ[ä½¿ç”¨æŒ‡å—](#vlmevalkit-è¯„æµ‹åç«¯) ğŸ”¥ğŸ”¥ğŸ”¥
- **[2024.06.29]** æ”¯æŒ**OpenCompass**ä½œä¸ºç¬¬ä¸‰æ–¹è¯„æµ‹æ¡†æ¶ï¼Œæˆ‘ä»¬å¯¹å…¶è¿›è¡Œäº†é«˜çº§å°è£…ï¼Œæ”¯æŒpipæ–¹å¼å®‰è£…ï¼Œç®€åŒ–äº†è¯„ä¼°ä»»åŠ¡é…ç½®ï¼Œ[ä½¿ç”¨æŒ‡å—](#opencompass-è¯„æµ‹åç«¯) ğŸ”¥ğŸ”¥ğŸ”¥
- **[2024.06.13]** EvalScopeä¸å¾®è°ƒæ¡†æ¶SWIFTè¿›è¡Œæ— ç¼å¯¹æ¥ï¼Œæä¾›LLMä»è®­ç»ƒåˆ°è¯„æµ‹çš„å…¨é“¾è·¯æ”¯æŒ ğŸš€ğŸš€ğŸš€
- **[2024.06.13]** æ¥å…¥Agentè¯„æµ‹é›†ToolBench ğŸš€ğŸš€ğŸš€

### ä½¿ç”¨è¯„æµ‹åç«¯ (Evaluation Backend)
EvalScopeæ”¯æŒä½¿ç”¨ç¬¬ä¸‰æ–¹è¯„æµ‹æ¡†æ¶å‘èµ·è¯„æµ‹ä»»åŠ¡ï¼Œæˆ‘ä»¬ç§°ä¹‹ä¸ºè¯„æµ‹åç«¯ (Evaluation Backend)ã€‚ç›®å‰æ”¯æŒçš„Evaluation Backendæœ‰ï¼š
- **Native**ï¼šEvalScopeè‡ªèº«çš„**é»˜è®¤è¯„æµ‹æ¡†æ¶**ï¼Œæ”¯æŒå¤šç§è¯„ä¼°æ¨¡å¼ï¼ŒåŒ…æ‹¬å•æ¨¡å‹è¯„ä¼°ã€ç«æŠ€åœºæ¨¡å¼ã€Baselineæ¨¡å‹å¯¹æ¯”æ¨¡å¼ç­‰ã€‚
- [OpenCompass](https://github.com/open-compass/opencompass)ï¼šé€šè¿‡EvalScopeä½œä¸ºå…¥å£ï¼Œå‘èµ·OpenCompassçš„è¯„æµ‹ä»»åŠ¡ï¼Œè½»é‡çº§ã€æ˜“äºå®šåˆ¶ã€æ”¯æŒä¸LLMå¾®è°ƒæ¡†æ¶[ModelScope Swift](https://github.com/modelscope/swift)çš„æ— ç¼é›†æˆã€‚
- [VLMEvalKit](https://github.com/open-compass/VLMEvalKit)ï¼šé€šè¿‡EvalScopeä½œä¸ºå…¥å£ï¼Œå‘èµ·VLMEvalKitçš„å¤šæ¨¡æ€è¯„æµ‹ä»»åŠ¡ï¼Œæ”¯æŒå¤šç§å¤šæ¨¡æ€æ¨¡å‹å’Œæ•°æ®é›†ï¼Œæ”¯æŒä¸LLMå¾®è°ƒæ¡†æ¶[ModelScope Swift](https://github.com/modelscope/swift)çš„æ— ç¼é›†æˆã€‚
- **ThirdParty**: ç¬¬ä¸‰æ–¹è¯„ä¼°ä»»åŠ¡ï¼Œå¦‚[ToolBench](evalscope/thirdparty/toolbench/README.md)ã€‚


### ä½¿ç”¨æœ¬åœ°æ•°æ®é›†
æ•°æ®é›†é»˜è®¤æ‰˜ç®¡åœ¨[ModelScope](https://modelscope.cn/datasets)ä¸Šï¼ŒåŠ è½½éœ€è¦è”ç½‘ã€‚å¦‚æœæ˜¯æ— ç½‘ç»œç¯å¢ƒï¼Œå¯ä»¥ä½¿ç”¨æœ¬åœ°æ•°æ®é›†ï¼Œæµç¨‹å¦‚ä¸‹ï¼š
#### 1. ä¸‹è½½æ•°æ®é›†åˆ°æœ¬åœ°
```shell
# å‡å¦‚å½“å‰æœ¬åœ°å·¥ä½œè·¯å¾„ä¸º /path/to/workdir
wget https://modelscope.oss-cn-beijing.aliyuncs.com/open_data/benchmark/data.zip
unzip data.zip
```
åˆ™è§£å‹åçš„æ•°æ®é›†è·¯å¾„ä¸ºï¼š/path/to/workdir/data ç›®å½•ä¸‹ï¼Œè¯¥ç›®å½•åœ¨åç»­æ­¥éª¤å°†ä¼šä½œä¸º--dataset-dirå‚æ•°çš„å€¼ä¼ å…¥

#### 2. ä½¿ç”¨æœ¬åœ°æ•°æ®é›†åˆ›å»ºè¯„ä¼°ä»»åŠ¡
```shell
python evalscope/run.py --model ZhipuAI/chatglm3-6b --template-type chatglm3 --datasets arc --dataset-hub Local --dataset-args '{"arc": {"local_path": "/path/to/workdir/data/arc"}}' --limit 10

# å‚æ•°è¯´æ˜
# --dataset-hub: æ•°æ®é›†æ¥æºï¼Œæšä¸¾å€¼ï¼š `ModelScope`, `Local`, `HuggingFace` (TO-DO)  é»˜è®¤ä¸º`ModelScope`
# --dataset-dir: å½“--dataset-hubä¸º`Local`æ—¶ï¼Œè¯¥å‚æ•°æŒ‡æœ¬åœ°æ•°æ®é›†è·¯å¾„; å¦‚æœ--dataset-hub è®¾ç½®ä¸º`ModelScope` or `HuggingFace`ï¼Œåˆ™è¯¥å‚æ•°çš„å«ä¹‰æ˜¯æ•°æ®é›†ç¼“å­˜è·¯å¾„ã€‚
```

#### 3. (å¯é€‰)åœ¨ç¦»çº¿ç¯å¢ƒåŠ è½½æ¨¡å‹å’Œè¯„æµ‹
æ¨¡å‹æ–‡ä»¶æ‰˜ç®¡åœ¨ModelScope Hubç«¯ï¼Œéœ€è¦è”ç½‘åŠ è½½ï¼Œå½“éœ€è¦åœ¨ç¦»çº¿ç¯å¢ƒåˆ›å»ºè¯„ä¼°ä»»åŠ¡æ—¶ï¼Œå¯å‚è€ƒä»¥ä¸‹æ­¥éª¤ï¼š
```shell
# 1. å‡†å¤‡æ¨¡å‹æœ¬åœ°æ–‡ä»¶å¤¹ï¼Œæ–‡ä»¶å¤¹ç»“æ„å‚è€ƒchatglm3-6bï¼Œé“¾æ¥ï¼šhttps://modelscope.cn/models/ZhipuAI/chatglm3-6b/files
# ä¾‹å¦‚ï¼Œå°†æ¨¡å‹æ–‡ä»¶å¤¹æ•´ä½“ä¸‹è½½åˆ°æœ¬åœ°è·¯å¾„ /path/to/ZhipuAI/chatglm3-6b

# 2. æ‰§è¡Œç¦»çº¿è¯„ä¼°ä»»åŠ¡
python evalscope/run.py --model /path/to/ZhipuAI/chatglm3-6b --template-type chatglm3 --datasets arc --dataset-hub Local --dataset-args '{"arc": {"local_path": "/path/to/workdir/data/arc"}}' --limit 10
```


### ä½¿ç”¨run_taskå‡½æ•°æäº¤è¯„ä¼°ä»»åŠ¡

#### 1. é…ç½®ä»»åŠ¡
```python
import torch
from evalscope.constants import DEFAULT_ROOT_CACHE_DIR

# ç¤ºä¾‹
your_task_cfg = {
        'model_args': {'revision': None, 'precision': torch.float16, 'device_map': 'auto'},
        'generation_config': {'do_sample': False, 'repetition_penalty': 1.0, 'max_new_tokens': 512},
        'dataset_args': {},
        'dry_run': False,
        'model': 'ZhipuAI/chatglm3-6b',
        'template_type': 'chatglm3', 
        'datasets': ['arc', 'hellaswag'],
        'work_dir': DEFAULT_ROOT_CACHE_DIR,
        'outputs': DEFAULT_ROOT_CACHE_DIR,
        'mem_cache': False,
        'dataset_hub': 'ModelScope',
        'dataset_dir': DEFAULT_ROOT_CACHE_DIR,
        'stage': 'all',
        'limit': 10,
        'debug': False
    }

```

#### 2. æ‰§è¡Œä»»åŠ¡
```python
from evalscope.run import run_task

run_task(task_cfg=your_task_cfg)
```


### ç«æŠ€åœºæ¨¡å¼ï¼ˆArenaï¼‰
ç«æŠ€åœºæ¨¡å¼å…è®¸å¤šä¸ªå€™é€‰æ¨¡å‹é€šè¿‡ä¸¤ä¸¤å¯¹æ¯”(pairwise battle)çš„æ–¹å¼è¿›è¡Œè¯„ä¼°ï¼Œå¹¶å¯ä»¥é€‰æ‹©å€ŸåŠ©AI Enhanced Auto-Reviewerï¼ˆAARï¼‰è‡ªåŠ¨è¯„ä¼°æµç¨‹æˆ–è€…äººå·¥è¯„ä¼°çš„æ–¹å¼ï¼Œæœ€ç»ˆå¾—åˆ°è¯„ä¼°æŠ¥å‘Šï¼Œæµç¨‹ç¤ºä¾‹å¦‚ä¸‹ï¼š
#### 1. ç¯å¢ƒå‡†å¤‡
```text
a. æ•°æ®å‡†å¤‡ï¼Œquestions dataæ ¼å¼å‚è€ƒï¼ševalscope/registry/data/question.jsonl
b. å¦‚æœéœ€è¦ä½¿ç”¨è‡ªåŠ¨è¯„ä¼°æµç¨‹ï¼ˆAARï¼‰ï¼Œåˆ™éœ€è¦é…ç½®ç›¸å…³ç¯å¢ƒå˜é‡ï¼Œæˆ‘ä»¬ä»¥GPT-4 based auto-revieweræµç¨‹ä¸ºä¾‹ï¼Œéœ€è¦é…ç½®ä»¥ä¸‹ç¯å¢ƒå˜é‡ï¼š
> export OPENAI_API_KEY=YOUR_OPENAI_API_KEY
```

#### 2. é…ç½®æ–‡ä»¶
```text
arenaè¯„ä¼°æµç¨‹çš„é…ç½®æ–‡ä»¶å‚è€ƒï¼š evalscope/registry/config/cfg_arena.yaml
å­—æ®µè¯´æ˜ï¼š
    questions_file: question dataçš„è·¯å¾„
    answers_gen: å€™é€‰æ¨¡å‹é¢„æµ‹ç»“æœç”Ÿæˆï¼Œæ”¯æŒå¤šä¸ªæ¨¡å‹ï¼Œå¯é€šè¿‡enableå‚æ•°æ§åˆ¶æ˜¯å¦å¼€å¯è¯¥æ¨¡å‹
    reviews_gen: è¯„ä¼°ç»“æœç”Ÿæˆï¼Œç›®å‰é»˜è®¤ä½¿ç”¨GPT-4ä½œä¸ºAuto-reviewerï¼Œå¯é€šè¿‡enableå‚æ•°æ§åˆ¶æ˜¯å¦å¼€å¯è¯¥æ­¥éª¤
    elo_rating: ELO rating ç®—æ³•ï¼Œå¯é€šè¿‡enableå‚æ•°æ§åˆ¶æ˜¯å¦å¼€å¯è¯¥æ­¥éª¤ï¼Œæ³¨æ„è¯¥æ­¥éª¤ä¾èµ–review_fileå¿…é¡»å­˜åœ¨
```

#### 3. æ‰§è¡Œè„šæœ¬
```shell
#Usage:
cd evalscope

# dry-runæ¨¡å¼ (æ¨¡å‹answeræ­£å¸¸ç”Ÿæˆï¼Œä½†ä¸“å®¶æ¨¡å‹ï¼Œå¦‚GPT-4ï¼Œä¸ä¼šè¢«è°ƒç”¨ï¼Œè¯„ä¼°ç»“æœä¼šéšæœºç”Ÿæˆ)
python evalscope/run_arena.py -c registry/config/cfg_arena.yaml --dry-run

# æ‰§è¡Œè¯„ä¼°æµç¨‹
python evalscope/run_arena.py --c registry/config/cfg_arena.yaml
```

#### 4. ç»“æœå¯è§†åŒ–

```shell
# Usage:
streamlit run viz.py --review-file evalscope/registry/data/qa_browser/battle.jsonl --category-file evalscope/registry/data/qa_browser/category_mapping.yaml
```


### å•æ¨¡å‹æ‰“åˆ†æ¨¡å¼ï¼ˆSingle modeï¼‰

è¿™ä¸ªæ¨¡å¼ä¸‹ï¼Œæˆ‘ä»¬åªå¯¹å•ä¸ªæ¨¡å‹è¾“å‡ºåšæ‰“åˆ†ï¼Œä¸åšä¸¤ä¸¤å¯¹æ¯”ã€‚
#### 1. é…ç½®æ–‡ä»¶
```text
è¯„ä¼°æµç¨‹çš„é…ç½®æ–‡ä»¶å‚è€ƒï¼š evalscope/registry/config/cfg_single.yaml
å­—æ®µè¯´æ˜ï¼š
    questions_file: question dataçš„è·¯å¾„
    answers_gen: å€™é€‰æ¨¡å‹é¢„æµ‹ç»“æœç”Ÿæˆï¼Œæ”¯æŒå¤šä¸ªæ¨¡å‹ï¼Œå¯é€šè¿‡enableå‚æ•°æ§åˆ¶æ˜¯å¦å¼€å¯è¯¥æ¨¡å‹
    reviews_gen: è¯„ä¼°ç»“æœç”Ÿæˆï¼Œç›®å‰é»˜è®¤ä½¿ç”¨GPT-4ä½œä¸ºAuto-reviewerï¼Œå¯é€šè¿‡enableå‚æ•°æ§åˆ¶æ˜¯å¦å¼€å¯è¯¥æ­¥éª¤
    rating_gen: rating ç®—æ³•ï¼Œå¯é€šè¿‡enableå‚æ•°æ§åˆ¶æ˜¯å¦å¼€å¯è¯¥æ­¥éª¤ï¼Œæ³¨æ„è¯¥æ­¥éª¤ä¾èµ–review_fileå¿…é¡»å­˜åœ¨
```
#### 2. æ‰§è¡Œè„šæœ¬
```shell
#Example:
python evalscope/run_arena.py --c registry/config/cfg_single.yaml
```

### Baselineæ¨¡å‹å¯¹æ¯”æ¨¡å¼ï¼ˆPairwise-baseline modeï¼‰

è¿™ä¸ªæ¨¡å¼ä¸‹ï¼Œæˆ‘ä»¬é€‰å®š baseline æ¨¡å‹ï¼Œå…¶ä»–æ¨¡å‹ä¸ baseline æ¨¡å‹åšå¯¹æ¯”è¯„åˆ†ã€‚è¿™ä¸ªæ¨¡å¼å¯ä»¥æ–¹ä¾¿çš„æŠŠæ–°æ¨¡å‹åŠ å…¥åˆ° Leaderboard ä¸­ï¼ˆåªéœ€è¦å¯¹æ–°æ¨¡å‹è·Ÿ baseline æ¨¡å‹è·‘ä¸€éæ‰“åˆ†å³å¯ï¼‰
#### 1. é…ç½®æ–‡ä»¶
```text
è¯„ä¼°æµç¨‹çš„é…ç½®æ–‡ä»¶å‚è€ƒï¼š evalscope/registry/config/cfg_pairwise_baseline.yaml
å­—æ®µè¯´æ˜ï¼š
    questions_file: question dataçš„è·¯å¾„
    answers_gen: å€™é€‰æ¨¡å‹é¢„æµ‹ç»“æœç”Ÿæˆï¼Œæ”¯æŒå¤šä¸ªæ¨¡å‹ï¼Œå¯é€šè¿‡enableå‚æ•°æ§åˆ¶æ˜¯å¦å¼€å¯è¯¥æ¨¡å‹
    reviews_gen: è¯„ä¼°ç»“æœç”Ÿæˆï¼Œç›®å‰é»˜è®¤ä½¿ç”¨GPT-4ä½œä¸ºAuto-reviewerï¼Œå¯é€šè¿‡enableå‚æ•°æ§åˆ¶æ˜¯å¦å¼€å¯è¯¥æ­¥éª¤
    rating_gen: rating ç®—æ³•ï¼Œå¯é€šè¿‡enableå‚æ•°æ§åˆ¶æ˜¯å¦å¼€å¯è¯¥æ­¥éª¤ï¼Œæ³¨æ„è¯¥æ­¥éª¤ä¾èµ–review_fileå¿…é¡»å­˜åœ¨
```
#### 2. æ‰§è¡Œè„šæœ¬
```shell
# Example:
python evalscope/run_arena.py --c registry/config/cfg_pairwise_baseline.yaml
```


## æ•°æ®é›†åˆ—è¡¨

| DatasetName        | Link                                                                                   | Status | Note |
|--------------------|----------------------------------------------------------------------------------------|--------|------|
| `mmlu`             | [mmlu](https://modelscope.cn/datasets/modelscope/mmlu/summary)                         | Active |      |
| `ceval`            | [ceval](https://modelscope.cn/datasets/modelscope/ceval-exam/summary)                  | Active |      |
| `gsm8k`            | [gsm8k](https://modelscope.cn/datasets/modelscope/gsm8k/summary)                       | Active |      |
| `arc`              | [arc](https://modelscope.cn/datasets/modelscope/ai2_arc/summary)                       | Active |      |
| `hellaswag`        | [hellaswag](https://modelscope.cn/datasets/modelscope/hellaswag/summary)               | Active |      |
| `truthful_qa`      | [truthful_qa](https://modelscope.cn/datasets/modelscope/truthful_qa/summary)           | Active |      |
| `competition_math` | [competition_math](https://modelscope.cn/datasets/modelscope/competition_math/summary) | Active |      |
| `humaneval`        | [humaneval](https://modelscope.cn/datasets/modelscope/humaneval/summary)               | Active |      |
| `bbh`              | [bbh](https://modelscope.cn/datasets/modelscope/bbh/summary)                           | Active |      |
| `race`             | [race](https://modelscope.cn/datasets/modelscope/race/summary)                         | Active |      |
| `trivia_qa`        | [trivia_qa](https://modelscope.cn/datasets/modelscope/trivia_qa/summary)               | To be intergrated |      |


## Leaderboard æ¦œå•
ModelScope LLM Leaderboardå¤§æ¨¡å‹è¯„æµ‹æ¦œå•æ—¨åœ¨æä¾›ä¸€ä¸ªå®¢è§‚ã€å…¨é¢çš„è¯„ä¼°æ ‡å‡†å’Œå¹³å°ï¼Œå¸®åŠ©ç ”ç©¶äººå‘˜å’Œå¼€å‘è€…äº†è§£å’Œæ¯”è¾ƒModelScopeä¸Šçš„æ¨¡å‹åœ¨å„ç§ä»»åŠ¡ä¸Šçš„æ€§èƒ½è¡¨ç°ã€‚

[Leaderboard](https://modelscope.cn/leaderboard/58/ranking?type=free)



## å®éªŒå’ŒæŠ¥å‘Š
å‚è€ƒï¼š [Experiments](./resources/experiments.md)

## æ€§èƒ½è¯„æµ‹å·¥å…·
å‚è€ƒï¼š [æ€§èƒ½æµ‹è¯•](evalscope/perf/README.md)

## TO-DO List
- [x] Agents evaluation
- [ ] vLLM
- [ ] Distributed evaluating
- [x] Multi-modal evaluation
- [ ] Benchmarks
  - [ ] GAIA
  - [ ] GPQA
  - [x] MBPP
- [ ] Auto-reviewer
  - [ ] Qwen-max


