# Custom Model Evaluation

## LLM Model Evaluation
Evaluation of large language models currently supports two methods: Native Evaluation and OpenCompass Evaluation.

### Method 1: Using Native Evaluation
```{seealso}
See [Basic Usage Guide: Submitting Evaluation Tasks with run_task](../get_started/basic_usage.md#3-use-the-run_task-function-to-submit-an-evaluation-task)
```

### Method 2: Using OpenCompass Evaluation
```{seealso}
See [OpenCompass Usage Guide](../user_guides/backend/opencompass_backend.md)
```
-----
## VLM Model Evaluation
Currently, evaluation of multimodal models only supports the VLMEvalKit backend.

### Using VLMEvalKit Backend
```{seealso}
See [VLMEvalKit Usage Guide](../user_guides/backend/vlmevalkit_backend.md)
```