# WNUT2017

## Overview

The WNUT2017 dataset is a collection of user-generated text from various social media platforms, like Twitter and YouTube, specifically designed for named entity recognition tasks focusing on emerging and unusual entities.

## Task Description

- **Task Type**: Emerging Entity Named Entity Recognition (NER)
- **Input**: User-generated social media text
- **Output**: Identified entity spans with types
- **Domain**: Social media, emerging entities

## Key Features

- User-generated text from multiple platforms
- Focus on emerging and unusual named entities
- Six entity types for diverse coverage
- Challenging informal text processing
- From WNUT 2017 shared task

## Evaluation Notes

- Default configuration uses **5-shot** evaluation
- Metrics: Precision, Recall, F1-Score, Accuracy
- Entity types: CORPORATION, CREATIVE-WORK, GROUP, LOCATION, PERSON, PRODUCT

## Properties

| Property | Value |
|----------|-------|
| **Benchmark Name** | `wnut2017` |
| **Dataset ID** | [extraordinarylab/wnut2017](https://modelscope.cn/datasets/extraordinarylab/wnut2017/summary) |
| **Paper** | N/A |
| **Tags** | `Knowledge`, `NER` |
| **Metrics** | `precision`, `recall`, `f1_score`, `accuracy` |
| **Default Shots** | 5-shot |
| **Evaluation Split** | `test` |
| **Train Split** | `train` |


## Data Statistics

| Metric | Value |
|--------|-------|
| Total Samples | 1,287 |
| Prompt Length (Mean) | 2665.65 chars |
| Prompt Length (Min/Max) | 2570 / 3093 chars |

## Sample Example

**Subset**: `default`

```json
{
  "input": [
    {
      "id": "f1e6b117",
      "content": "Here are some examples of named entity recognition:\n\nInput:\n@paulwalk It 's the view from where I 'm living for two weeks . Empire State Building = ESB . Pretty bad storm here last evening .\n\nOutput:\n<response>@paulwalk It 's the view from wh ... [TRUNCATED] ... he most specific entity type.\n7. Ensure every opening tag has a matching closing tag.\n\nText to process:\n& gt ; * The soldier was killed when another avalanche hit an army barracks in the northern area of Sonmarg , said a military spokesman .\n"
    }
  ],
  "target": "<response>& gt ; * The soldier was killed when another avalanche hit an army barracks in the northern area of <location>Sonmarg</location> , said a military spokesman .</response>",
  "id": 0,
  "group_id": 0,
  "metadata": {
    "tokens": [
      "&",
      "gt",
      ";",
      "*",
      "The",
      "soldier",
      "was",
      "killed",
      "when",
      "another",
      "avalanche",
      "hit",
      "an",
      "army",
      "barracks",
      "in",
      "the",
      "northern",
      "area",
      "of",
      "Sonmarg",
      ",",
      "said",
      "a",
      "military",
      "spokesman",
      "."
    ],
    "ner_tags": [
      "O",
      "O",
      "O",
      "O",
      "O",
      "O",
      "O",
      "O",
      "O",
      "O",
      "O",
      "O",
      "O",
      "O",
      "O",
      "O",
      "O",
      "O",
      "O",
      "O",
      "B-LOCATION",
      "O",
      "O",
      "O",
      "O",
      "O",
      "O"
    ]
  }
}
```

*Note: Some content was truncated for display.*

## Prompt Template

**Prompt Template:**
```text
You are a named entity recognition system that identifies the following entity types:
{entities}

Process the provided text and mark all named entities with XML-style tags.

For example:
<person>John Smith</person> works at <organization>Google</organization> in <location>Mountain View</location>.

Available entity tags: {entity_list}

INSTRUCTIONS:
1. Wrap your entire response in <response>...</response> tags.
2. Inside these tags, include the original text with entity tags inserted.
3. Do not change the original text in any way (preserve spacing, punctuation, case, etc.).
4. Tag ALL entities you can identify using the exact tag names provided.
5. Do not include explanations, just the tagged text.
6. If entity spans overlap, choose the most specific entity type.
7. Ensure every opening tag has a matching closing tag.

Text to process:
{text}

```

<details>
<summary>Few-shot Template</summary>

```text
Here are some examples of named entity recognition:

{fewshot}

You are a named entity recognition system that identifies the following entity types:
{entities}

Process the provided text and mark all named entities with XML-style tags.

For example:
<person>John Smith</person> works at <organization>Google</organization> in <location>Mountain View</location>.

Available entity tags: {entity_list}

INSTRUCTIONS:
1. Wrap your entire response in <response>...</response> tags.
2. Inside these tags, include the original text with entity tags inserted.
3. Do not change the original text in any way (preserve spacing, punctuation, case, etc.).
4. Tag ALL entities you can identify using the exact tag names provided.
5. Do not include explanations, just the tagged text.
6. If entity spans overlap, choose the most specific entity type.
7. Ensure every opening tag has a matching closing tag.

Text to process:
{text}

```

</details>

## Usage

### Using CLI

```bash
evalscope eval \
    --model YOUR_MODEL \
    --api-url OPENAI_API_COMPAT_URL \
    --api-key EMPTY_TOKEN \
    --datasets wnut2017 \
    --limit 10  # Remove this line for formal evaluation
```

### Using Python

```python
from evalscope import run_task
from evalscope.config import TaskConfig

task_cfg = TaskConfig(
    model='YOUR_MODEL',
    api_url='OPENAI_API_COMPAT_URL',
    api_key='EMPTY_TOKEN',
    datasets=['wnut2017'],
    limit=10,  # Remove this line for formal evaluation
)

run_task(task_cfg=task_cfg)
```


